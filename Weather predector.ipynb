{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84453ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pickle as pk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "            accuracy_score,\n",
    "            precision_score, \n",
    "            recall_score,\n",
    "            f1_score,\n",
    "            roc_auc_score,\n",
    "            confusion_matrix,\n",
    "            precision_recall_curve,\n",
    "            auc,\n",
    "            mean_absolute_error,\n",
    "            mean_squared_error,\n",
    "            r2_score)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"This Pipeline instance is not fitted yet\")\n",
    "\n",
    "class GLDASFetcher:\n",
    "    def __init__(self, username=None, password=None):\n",
    "        \"\"\"\n",
    "        Initialize GLDAS/POWER fetcher (username/password only needed for GLDAS OPeNDAP, \n",
    "        not for NASA POWER API).\n",
    "        \"\"\"\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "\n",
    "        # GLDAS variable names mapped to NASA POWER parameters\n",
    "        self.variables_map = {\n",
    "            'temp': ['T2M_MAX', 'T2M_MIN'],           # Daily max/min temp\n",
    "            'humidity': ['QV2M'],                     # Specific humidity\n",
    "            'pressure': ['PS'],                       # Surface pressure\n",
    "            'precipitation': ['PRECTOTCORR'],         # Corrected daily precipitation\n",
    "            'solar_rad': ['ALLSKY_SFC_SW_DWN'],       # Solar radiation\n",
    "            'wind_speed': ['WS2M']                    # Wind speed\n",
    "        }\n",
    "\n",
    "    def get_data(self, lat, lon, start_date, end_date, variables=None):\n",
    "        \"\"\"\n",
    "        Fetch daily NASA POWER data for a given location & date range.\n",
    "        \"\"\"\n",
    "        variables = variables or list(self.variables_map.keys())\n",
    "    \n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    \n",
    "        # Collect POWER parameter codes\n",
    "        power_params = []\n",
    "        for var in variables:\n",
    "            power_params.extend(self.variables_map.get(var, []))\n",
    "    \n",
    "        params = {\n",
    "            'parameters': ','.join(power_params),\n",
    "            'community': 'RE',\n",
    "            'longitude': lon,\n",
    "            'latitude': lat,\n",
    "            'start': start_date.replace(\"-\", \"\"),\n",
    "            'end': end_date.replace(\"-\", \"\"),\n",
    "            'format': 'JSON'\n",
    "        }\n",
    "    \n",
    "        print(f\"üåç Fetching NASA POWER data for ({lat}, {lon}) from {start_date} to {end_date} ...\")\n",
    "        response = requests.get(base_url, params=params, timeout=60)\n",
    "    \n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå API error {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "        data = response.json()['properties']['parameter']\n",
    "    \n",
    "        # Build dataframe manually\n",
    "        records = {}\n",
    "        for var, timeseries in data.items():\n",
    "            for date_str, value in timeseries.items():\n",
    "                if date_str not in records:\n",
    "                    records[date_str] = {}\n",
    "                records[date_str][var] = value\n",
    "    \n",
    "        # Convert dict -> DataFrame\n",
    "        df = pd.DataFrame.from_dict(records, orient='index')\n",
    "        df.index = pd.to_datetime(df.index, format=\"%Y%m%d\")  # Proper date parsing\n",
    "        df.index.name = \"date\"\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        # Add metadata\n",
    "        df['latitude'] = lat\n",
    "        df['longitude'] = lon\n",
    "\n",
    "        columns = [\"date\",\"temp_max\",\"temp_min\",\"humidity_specific\",\"pressure\",\"precipitation_total\",\"solar_radiation\",\"wind_speed\",\"lat\",\"lon\"]\n",
    "        df.columns = columns\n",
    "        print(f\"‚úÖ Retrieved {len(df)} daily records\")\n",
    "        return df\n",
    "\n",
    "    def get_bulk_data(self, locations, start_date, end_date, variables=None):\n",
    "        \"\"\"\n",
    "        Fetch data for multiple locations.\n",
    "\n",
    "        Args:\n",
    "            locations (list): [(lat, lon), ...]\n",
    "            start_date (str): YYYY-MM-DD\n",
    "            end_date (str): YYYY-MM-DD\n",
    "            variables (list): Variables list\n",
    "\n",
    "        Returns:\n",
    "            dict: { \"lat_lon\": DataFrame }\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for lat, lon in locations:\n",
    "            df = self.get_data(lat, lon, start_date, end_date, variables)\n",
    "            if not df.empty:\n",
    "                key = f\"lat_{lat}_lon_{lon}\"\n",
    "                results[key] = df\n",
    "        return results\n",
    "\n",
    "    def to_csv(self, data, filename):\n",
    "        \"\"\"Export single DataFrame or dict of DataFrames to CSV\"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            all_data = []\n",
    "            for loc, df in data.items():\n",
    "                df_copy = df.copy()\n",
    "                df_copy['location'] = loc\n",
    "                all_data.append(df_copy)\n",
    "            combined = pd.concat(all_data, ignore_index=True)\n",
    "            combined.to_csv(filename, index=False)\n",
    "        else:\n",
    "            data.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_location_by_address(self, address):\n",
    "        \"\"\"Return location data from an address, retrying if failed.\"\"\"\n",
    "        time.sleep(1)\n",
    "        geolocator = Nominatim(user_agent=\"gldas_fetcher\")\n",
    "        try:\n",
    "            return geolocator.geocode(address).raw\n",
    "        except:\n",
    "            return self.get_location_by_address(address)  # Recursive retry\n",
    "\n",
    "\n",
    "    def main():\n",
    "        \"\"\"Example usage with NASA data\"\"\"\n",
    "        \n",
    "        print(\"üöÄ NASA GLDAS Data Fetcher\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        \n",
    "        username = \"mahmoudmo12\"\n",
    "        password = \"Mahmoudmetawe12@\"\n",
    "        \n",
    "    \n",
    "        # Initialize with real credentials\n",
    "        fetcher = GLDASFetcher(username=username, password=password)\n",
    "        city = input(\"enter the city: \")\n",
    "        \n",
    "        \n",
    "        location = fetcher.get_location_by_address(city)\n",
    "        lat = location[\"lat\"]\n",
    "        lon = location[\"lon\"]\n",
    "        city_name = location['display_name']\n",
    "        #start_date = input(\"enter the start date formula (yyyy-mm-dd): \")\n",
    "        #end_date = input(\"enter the end date formula (yyyy-mm-dd): \")\n",
    "        \n",
    "        # Test with a single location\n",
    "        print(f\"\\nüåç Fetching DAILY data for {city_name}\")\n",
    "        \n",
    "        data = fetcher.get_data(\n",
    "            lat=lat,\n",
    "            lon=lon,\n",
    "            start_date=\"1984-01-01\",\n",
    "            end_date=\"2025-10-20\",\n",
    "            variables=['temp', 'humidity', 'pressure', 'precipitation', 'solar_rad', 'wind_speed']\n",
    "        )\n",
    "        \n",
    "        if not data.empty:\n",
    "            print(f\"\\n‚úÖ SUCCESS! Retrieved {len(data)} real data points\")\n",
    "            print(f\"üìã Columns: {list(data.columns)}\")\n",
    "            \n",
    "            # Export real data\n",
    "            fetcher.to_csv(data, \"nasa_daily_weather_data.csv\")\n",
    "            # import the data\n",
    "            df = pd.read_csv(\"nasa_daily_weather_data.csv\")\n",
    "        else:\n",
    "            print(\"‚ùå\")     \n",
    "        return df \n",
    "\n",
    "\n",
    "\n",
    "class WeatherForecaster:\n",
    "    def __init__(self, data_path, pipeline_path=\"pipeline_ensemble.pkl\"):\n",
    "        self.data_path = data_path\n",
    "        self.pipeline_path = pipeline_path\n",
    "        self.df, _ = self._wrangle(data_path, 'humidity_specific')\n",
    "        self.columns = self.df.columns\n",
    "        self.targets = self.columns.drop([\"date\", \"day_of_year\", \"lat\", \"lon\", \"did_rain\"])\n",
    "        self.models = None\n",
    "        self.pipeline = None\n",
    "        self.best_threshold = None\n",
    "\n",
    "    #wrangle without noise columns\n",
    "    def _wrangle(self,path,target=None):\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        day_of_year = df['date'].dt.dayofyear\n",
    "        df['day_of_year'] = day_of_year\n",
    "        # getting the target column with the date for the model \n",
    "        df_prophet = df[['date', target]].rename(columns={'date': 'ds', target: 'y'})\n",
    "\n",
    "        did_rain = [0 if i < 0.2 else 1 for i in df['precipitation_total']]\n",
    "        df['did_rain'] = did_rain   \n",
    "        \n",
    "         # the nan val in nasa api is -999\n",
    "        df.replace(-999.0000,np.nan,inplace=True)\n",
    "        df_prophet.replace(-999.0000,np.nan,inplace=True)\n",
    "        #drop noise\n",
    "        df.drop(columns=[\"wind_speed\",\"precipitation_total\"],inplace=True)\n",
    "        # drop nulls\n",
    "        \n",
    "        df.dropna(inplace=True)\n",
    "        df_prophet.dropna(inplace=True)\n",
    "        \n",
    "        return df,df_prophet\n",
    "\n",
    "    def train_and_save_prophet(self):\n",
    "        for target in self.targets:\n",
    "            _, df_prophet = self._wrangle(self.data_path, target)\n",
    "            model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "            model.fit(df_prophet)\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            with open(filename, 'wb') as file:\n",
    "                pk.dump(model, file)\n",
    "            print(f\"model for {target} is saved\")\n",
    "\n",
    "    def gathering_models(self):\n",
    "        all_models = []\n",
    "        for target in self.targets:\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            with open(filename, 'rb') as file:\n",
    "                all_models.append(pk.load(file))\n",
    "        self.models = all_models\n",
    "        return all_models\n",
    "\n",
    "    def predict_func(self, start_date, interval):\n",
    "        \n",
    "        \"\"\"\n",
    "        Internal helper to forecast all weather variables for a given time interval.\n",
    "\n",
    "        Args:\n",
    "            start_date (str): The starting date in 'YYYY-MM-DD' format.\n",
    "            interval (int): The number of future days to forecast.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the forecasted weather variables,\n",
    "                          ready to be used by the rain prediction pipeline.\n",
    "        \"\"\"\n",
    "        # 1. Create a DataFrame with the future dates for Prophet\n",
    "        future_dates_df = pd.DataFrame({\n",
    "            'ds': pd.date_range(start=start_date, periods=interval, freq='D')\n",
    "        })\n",
    "\n",
    "        # 2. Start building the final DataFrame, beginning with the date column\n",
    "        future_weather_df = pd.DataFrame({'date': future_dates_df['ds']})\n",
    "        # 3. Loop through each Prophet model to forecast its specific weather variable\n",
    "        #    This assumes self.targets and self.models are in the same order.\n",
    "        print(\"Forecasting future weather conditions...\")\n",
    "        for target_variable, model in zip(self.targets, self.models):\n",
    "            # Use the model to predict values for the entire date range\n",
    "            forecast = model.predict(future_dates_df)\n",
    "\n",
    "            # Extract the forecasted values ('yhat') and the dates ('ds')\n",
    "            future_values = forecast[['ds', 'yhat']].rename(\n",
    "                columns={'ds': 'date', 'yhat': target_variable}\n",
    "            )\n",
    "\n",
    "            # Merge this forecast into our main weather DataFrame\n",
    "            future_weather_df = pd.merge(future_weather_df, future_values, on='date')\n",
    "        \n",
    "        # 4. Ensure the column order matches exactly what the pipeline was trained on\n",
    "        required_columns = ['date', 'temp_max', 'temp_min', 'humidity_specific', 'pressure', 'solar_radiation']\n",
    "        future_weather_df = future_weather_df[required_columns]\n",
    "\n",
    "        print(\"Weather forecast complete.\")\n",
    "        return future_weather_df\n",
    "\n",
    "    class ProphetWrapper(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, model):\n",
    "            self.model = model\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            future = pd.DataFrame({'ds': X.flatten()})\n",
    "            forecast = self.model.predict(future)\n",
    "            return forecast[['yhat']].values\n",
    "\n",
    "    def save_pipeline(self):\n",
    "        \n",
    "        # 1. Define your new feature set (after creating lags, etc.)\n",
    "        # The date is still needed for Prophet, other features for XGBoost\n",
    "        date_feature = ['date'] \n",
    "        weather_features = ['temp_max', 'temp_min', 'humidity_specific', 'pressure', \"solar_radiation\"] \n",
    "        \n",
    "        # 2. Create the Prophet forecasting part (same as your code)\n",
    "        p_models = self.models\n",
    "        wrapped_prophets = [\n",
    "            (f'prophet_{i}', self.ProphetWrapper(model))\n",
    "            for i, model in enumerate(p_models)]\n",
    "        prophet_forecasters = FeatureUnion(wrapped_prophets)\n",
    "        prophet_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer([('date_selector', 'passthrough', [0])])), # Select only the date column\n",
    "            ('prophet_features', prophet_forecasters)\n",
    "        ])\n",
    "        # Features and target\n",
    "        X = self.df.drop(columns='did_rain')\n",
    "        y = self.df['did_rain'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        neg, pos = np.bincount(y)   # count 0s and 1s in did_rain\n",
    "        imbalance_ratio = neg / pos\n",
    "        # 3. Create a pipeline for your standard numerical weather features\n",
    "        weather_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer([('weather_selector', 'passthrough', [i for i, col in enumerate(X.columns) if col in weather_features])])),\n",
    "            ('scaler', StandardScaler()) # Scaling is good practice for XGBoost\n",
    "        ])\n",
    "        \n",
    "        # 4. Combine them using FeatureUnion\n",
    "        combined_features = FeatureUnion([\n",
    "            ('prophet_pipeline', prophet_pipeline),\n",
    "            ('weather_pipeline', weather_pipeline)\n",
    "        ])\n",
    "        \n",
    "        # 5. Create the final, complete pipeline\n",
    "        final_pipeline = Pipeline([\n",
    "            ('features', combined_features),\n",
    "            ('xgb_classifier', XGBClassifier(n_estimators=550,\n",
    "                                             max_depth=8,\n",
    "                                             learning_rate=0.05,\n",
    "                                             subsample=0.7,\n",
    "                                             scale_pos_weight=imbalance_ratio,\n",
    "                                             random_state=42)) # Your XGBoost model here\n",
    "        ])\n",
    "        #over_sampler = RandomOverSampler(sampling_strategy=\"all\",random_state=42)\n",
    "        #X_train_over,y_train_over = over_sampler.fit_resample(X_train,y_train)\n",
    "        # Now fit this final_pipeline on your data that includes ALL columns\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        joblib.dump(final_pipeline, self.pipeline_path)\n",
    "\n",
    "        # Evaluation \n",
    "        y_pred = final_pipeline.predict(X_test)\n",
    "        y_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        # After fitting the model and getting y_proba\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "        \n",
    "        # Calculate F1 score for each threshold\n",
    "        # Add a small epsilon to avoid division by zero :1e-9\n",
    "        f1_scores = 2 * recall * precision / (recall + precision + 1e-9)\n",
    "        \n",
    "        # Find the threshold that gives the best F1 score\n",
    "        best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        \n",
    "        print(f\"Best Threshold for F1 Score: {best_threshold*100} %\")\n",
    "        \n",
    "        self.best_threshold = best_threshold\n",
    "        \n",
    "        y_pred = (y_proba >= best_threshold).astype(int)\n",
    "        \n",
    "        print(\"\\nüìä Model Evaluation on Test Set\")\n",
    "        \n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "        print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "        print(\"PR AUC:\", pr_auc)\n",
    "        \n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred)) \n",
    "    def calculate_metrics(self,test, train, model):     \n",
    "        # predictions\n",
    "        train_pred = model.predict(train)\n",
    "        test_pred = model.predict(test)\n",
    "    \n",
    "        y_true = test['y'].values\n",
    "        y_pred = test_pred['yhat'].values\n",
    "    \n",
    "        y_train = train['y'].values\n",
    "        yhat_train = train_pred['yhat'].values\n",
    "    \n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "    \n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'R2': r2_score(y_true, y_pred),\n",
    "            \"SMAPE\": smape,\n",
    "            'Mean_Error': np.mean(y_pred - y_true),  # Bias\n",
    "            'Training MAE': mean_absolute_error(y_train, yhat_train)\n",
    "        }\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "        return metrics\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Main function to generate a rain and weather forecast for a specified interval.\n",
    "        \"\"\"\n",
    "        # 1. Load the main rain prediction pipeline\n",
    "        self.pipeline = joblib.load(self.pipeline_path)\n",
    "        \n",
    "        # 2. Get the date and interval from the user\n",
    "        start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "        interval = int(input(\"Enter the number of days to forecast: \"))\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 3. Call the helper function to get the weather forecast for the full interval.\n",
    "        #    This `weather_preds_df` contains all the features needed for the next step.\n",
    "        weather_preds_df = self.predict_func(start_date, interval)\n",
    "\n",
    "        # 4. Use the complete weather forecast to predict the probability of rain.\n",
    "        #    The pipeline receives a DataFrame with multiple rows and 6 columns, just as it expects.\n",
    "        rain_probabilities = self.pipeline.predict_proba(weather_preds_df)\n",
    "\n",
    "        # 5. Format the rain probability results into a clean DataFrame\n",
    "        proba_df = pd.DataFrame(\n",
    "            (rain_probabilities * 100).round(2),\n",
    "            columns=[\"Prob. of No Rain (%)\", \"Prob. of Rain (%)\"],\n",
    "            index=weather_preds_df['date']  # Use the future dates as the index\n",
    "        )\n",
    "        \n",
    "        best_threshold_percent = self.best_threshold * 100\n",
    "        proba_df[\"Recommendation\"] = proba_df['Prob. of Rain (%)'].apply(\n",
    "            lambda x: \"Take an umbrella! ‚òî\" if x >= best_threshold_percent else \"Enjoy the clear skies! ‚òÄÔ∏è\")\n",
    "        \n",
    "\n",
    "        # 7. Return both the rain probabilities and the detailed weather predictions\n",
    "        return proba_df, weather_preds_df.set_index('date')\n",
    "    \n",
    "    def Prophet_metrics(self):\n",
    "        # metrics calculation for each model of the prophets models\n",
    "        test_list = []\n",
    "        train_list = []\n",
    "        \n",
    "        for i in self.targets:\n",
    "            _,df_prophet = self._wrangle(\"nasa_daily_weather_data.csv\",i)\n",
    "        \n",
    "            # Split the data for the prophet models metrics (temp,humidity,...)\n",
    "            train_df, test_df = train_test_split(df_prophet, test_size=0.2, shuffle=False)\n",
    "        \n",
    "            train_list.append(train_df)\n",
    "        \n",
    "            test_list.append(test_df)\n",
    "        models = self.gathering_models()\n",
    "        for i in range(len(self.targets)):\n",
    "            print(\"=\"*70)\n",
    "            print(f\"Evaluation Results {self.targets[i]}\")\n",
    "            wf.calculate_metrics(test_list[i],train_list[i],models[i])\n",
    "            print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff7c6682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NASA GLDAS Data Fetcher\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter the city:  ÿ≥ÿ±ÿ≥ ÿßŸÑŸÑŸäÿßŸÜ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Fetching DAILY data for ÿ≥ÿ±ÿ≥ ÿßŸÑŸÑŸäÿßŸÜ, ÿßŸÑŸÖŸÜŸàŸÅŸäÿ©, 32861, ŸÖÿµÿ±\n",
      "üåç Fetching NASA POWER data for (30.4439168, 30.9707264) from 1984-01-01 to 2025-10-20 ...\n",
      "‚úÖ Retrieved 15269 daily records\n",
      "\n",
      "‚úÖ SUCCESS! Retrieved 15269 real data points\n",
      "üìã Columns: ['date', 'temp_max', 'temp_min', 'humidity_specific', 'pressure', 'precipitation_total', 'solar_radiation', 'wind_speed', 'lat', 'lon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for temp_max is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for temp_min is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for humidity_specific is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for pressure is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:24:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for solar_radiation is saved\n",
      "Best Threshold for F1 Score: 42.76325607299805 %\n",
      "\n",
      "üìä Model Evaluation on Test Set\n",
      "Accuracy: 0.9050425671250819\n",
      "Precision: 0.5849056603773585\n",
      "Recall: 0.5406976744186046\n",
      "F1 Score: 0.5619335347432024\n",
      "ROC AUC: 0.8451434180039475\n",
      "PR AUC: 0.5649016525912377\n",
      "Confusion Matrix:\n",
      " [[2578  132]\n",
      " [ 158  186]]\n",
      "======================================================================\n",
      "Evaluation Results temp_max\n",
      "MAE: 2.15\n",
      "RMSE: 2.87\n",
      "R2: 0.87\n",
      "SMAPE: 7.52\n",
      "Mean_Error: 0.01\n",
      "Training MAE: 2.25\n",
      "======================================================================\n",
      "======================================================================\n",
      "Evaluation Results temp_min\n",
      "MAE: 1.41\n",
      "RMSE: 1.82\n",
      "R2: 0.90\n",
      "SMAPE: 10.63\n",
      "Mean_Error: 0.01\n",
      "Training MAE: 1.41\n",
      "======================================================================\n",
      "======================================================================\n",
      "Evaluation Results humidity_specific\n",
      "MAE: 0.91\n",
      "RMSE: 1.15\n",
      "R2: 0.78\n",
      "SMAPE: 11.29\n",
      "Mean_Error: -0.01\n",
      "Training MAE: 0.87\n",
      "======================================================================\n",
      "======================================================================\n",
      "Evaluation Results pressure\n",
      "MAE: 0.22\n",
      "RMSE: 0.30\n",
      "R2: 0.64\n",
      "SMAPE: 0.22\n",
      "Mean_Error: 0.01\n",
      "Training MAE: 0.24\n",
      "======================================================================\n",
      "======================================================================\n",
      "Evaluation Results solar_radiation\n",
      "MAE: 0.38\n",
      "RMSE: 0.59\n",
      "R2: 0.90\n",
      "SMAPE: 7.73\n",
      "Mean_Error: 0.00\n",
      "Training MAE: 0.42\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start date (YYYY-MM-DD):  2025-11-01\n",
      "Enter the number of days to forecast:  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Forecasting future weather conditions...\n",
      "Weather forecast complete.\n",
      "\n",
      "Weather predictions:\n",
      "             temp_max   temp_min  humidity_specific    pressure  \\\n",
      "date                                                              \n",
      "2025-11-01  30.193481  17.228217           9.538518  101.215459   \n",
      "2025-11-02  30.014445  17.080371           9.483051  101.222270   \n",
      "2025-11-03  29.837041  16.931954           9.427627  101.228998   \n",
      "2025-11-04  29.660950  16.783262           9.372107  101.235632   \n",
      "2025-11-05  29.485819  16.634568           9.316350  101.242168   \n",
      "2025-11-06  29.311272  16.486122           9.260215  101.248603   \n",
      "2025-11-07  29.136922  16.338146           9.203565  101.254938   \n",
      "\n",
      "            solar_radiation  \n",
      "date                         \n",
      "2025-11-01         4.355070  \n",
      "2025-11-02         4.316422  \n",
      "2025-11-03         4.278837  \n",
      "2025-11-04         4.242278  \n",
      "2025-11-05         4.206702  \n",
      "2025-11-06         4.172049  \n",
      "2025-11-07         4.138254  \n",
      "\n",
      "Rain probabilities:\n",
      "            Prob. of No Rain (%)  Prob. of Rain (%)             Recommendation\n",
      "date                                                                          \n",
      "2025-11-01             99.589996               0.41  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-02             99.260002               0.74  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-03             94.800003               5.20  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-04             95.570000               4.43  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-05             95.980003               4.02  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-06             97.889999               2.11  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-11-07             93.730003               6.27  Enjoy the clear skies! ‚òÄÔ∏è\n"
     ]
    }
   ],
   "source": [
    "#fetch the data according to the location \n",
    "GLDASFetcher.main()\n",
    "\n",
    "wf = WeatherForecaster(\"nasa_daily_weather_data.csv\")\n",
    "\n",
    "# Train Prophet models and save them\n",
    "wf.train_and_save_prophet()\n",
    "\n",
    "# Load Prophet models into memory\n",
    "wf.gathering_models()\n",
    "\n",
    "# Save ensemble pipeline\n",
    "wf.save_pipeline()\n",
    "\n",
    "wf.Prophet_metrics()\n",
    "# Make predictions\n",
    "proba_df, weather_preds = wf.model()\n",
    "\n",
    "print(\"\\nWeather predictions:\")\n",
    "print(weather_preds)\n",
    "print(\"\\nRain probabilities:\")\n",
    "print(proba_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c0ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>humidity_specific</th>\n",
       "      <th>pressure</th>\n",
       "      <th>solar_radiation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-01</th>\n",
       "      <td>30.193481</td>\n",
       "      <td>17.228217</td>\n",
       "      <td>9.538518</td>\n",
       "      <td>101.215459</td>\n",
       "      <td>4.355070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-02</th>\n",
       "      <td>30.014445</td>\n",
       "      <td>17.080371</td>\n",
       "      <td>9.483051</td>\n",
       "      <td>101.222270</td>\n",
       "      <td>4.316422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-03</th>\n",
       "      <td>29.837041</td>\n",
       "      <td>16.931954</td>\n",
       "      <td>9.427627</td>\n",
       "      <td>101.228998</td>\n",
       "      <td>4.278837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-04</th>\n",
       "      <td>29.660950</td>\n",
       "      <td>16.783262</td>\n",
       "      <td>9.372107</td>\n",
       "      <td>101.235632</td>\n",
       "      <td>4.242278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-05</th>\n",
       "      <td>29.485819</td>\n",
       "      <td>16.634568</td>\n",
       "      <td>9.316350</td>\n",
       "      <td>101.242168</td>\n",
       "      <td>4.206702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-06</th>\n",
       "      <td>29.311272</td>\n",
       "      <td>16.486122</td>\n",
       "      <td>9.260215</td>\n",
       "      <td>101.248603</td>\n",
       "      <td>4.172049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07</th>\n",
       "      <td>29.136922</td>\n",
       "      <td>16.338146</td>\n",
       "      <td>9.203565</td>\n",
       "      <td>101.254938</td>\n",
       "      <td>4.138254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             temp_max   temp_min  humidity_specific    pressure  \\\n",
       "date                                                              \n",
       "2025-11-01  30.193481  17.228217           9.538518  101.215459   \n",
       "2025-11-02  30.014445  17.080371           9.483051  101.222270   \n",
       "2025-11-03  29.837041  16.931954           9.427627  101.228998   \n",
       "2025-11-04  29.660950  16.783262           9.372107  101.235632   \n",
       "2025-11-05  29.485819  16.634568           9.316350  101.242168   \n",
       "2025-11-06  29.311272  16.486122           9.260215  101.248603   \n",
       "2025-11-07  29.136922  16.338146           9.203565  101.254938   \n",
       "\n",
       "            solar_radiation  \n",
       "date                         \n",
       "2025-11-01         4.355070  \n",
       "2025-11-02         4.316422  \n",
       "2025-11-03         4.278837  \n",
       "2025-11-04         4.242278  \n",
       "2025-11-05         4.206702  \n",
       "2025-11-06         4.172049  \n",
       "2025-11-07         4.138254  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc5d76f-426c-4f2d-abd9-44147e231eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob. of No Rain (%)</th>\n",
       "      <th>Prob. of Rain (%)</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-01</th>\n",
       "      <td>99.589996</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-02</th>\n",
       "      <td>99.260002</td>\n",
       "      <td>0.74</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-03</th>\n",
       "      <td>94.800003</td>\n",
       "      <td>5.20</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-04</th>\n",
       "      <td>95.570000</td>\n",
       "      <td>4.43</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-05</th>\n",
       "      <td>95.980003</td>\n",
       "      <td>4.02</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-06</th>\n",
       "      <td>97.889999</td>\n",
       "      <td>2.11</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-07</th>\n",
       "      <td>93.730003</td>\n",
       "      <td>6.27</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prob. of No Rain (%)  Prob. of Rain (%)             Recommendation\n",
       "date                                                                          \n",
       "2025-11-01             99.589996               0.41  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-02             99.260002               0.74  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-03             94.800003               5.20  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-04             95.570000               4.43  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-05             95.980003               4.02  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-06             97.889999               2.11  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-11-07             93.730003               6.27  Enjoy the clear skies! ‚òÄÔ∏è"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04badfc8-f540-4a80-8ea4-9c2fd2484cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
