{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "799be353-ca1b-470a-9f6c-c51c6feef47f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NASA GLDAS Data Fetcher & Rain Forecaster\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the city name (e.g., 'Cairo, Egypt'):  giza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Geocoded giza to: ÿßŸÑÿ¨Ÿäÿ≤ÿ©, 12524, ŸÖÿµÿ± (29.9870753, 31.2118063)\n",
      "üåç Fetching NASA POWER data for (29.9870753, 31.2118063) from 1984-01-01 to 2025-10-31 ...\n",
      "‚úÖ Retrieved 15280 daily records\n",
      "\n",
      "‚úÖ Data successfully saved to nasa_daily_weather_data.csv\n",
      "\n",
      "üßπ Loading and cleaning data from nasa_daily_weather_data.csv...\n",
      "‚úÖ Data cleaning complete.\n",
      "\n",
      "üöÇ Training Prophet models for each weather variable...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:57:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:57:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'temp_max' trained and saved to prophet_model_temp_max.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:57:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'temp_min' trained and saved to prophet_model_temp_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:58:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'humidity_specific' trained and saved to prophet_model_humidity_specific.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:58:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'pressure' trained and saved to prophet_model_pressure.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:58:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:58:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'solar_radiation' trained and saved to prophet_model_solar_radiation.pkl\n",
      "\n",
      "üìà Evaluating individual Prophet (weather) models...\n",
      "\n",
      "üì• Loading all trained Prophet models...\n",
      "   -> Loaded prophet_model_temp_max.pkl\n",
      "   -> Loaded prophet_model_temp_min.pkl\n",
      "   -> Loaded prophet_model_humidity_specific.pkl\n",
      "   -> Loaded prophet_model_pressure.pkl\n",
      "   -> Loaded prophet_model_solar_radiation.pkl\n",
      "‚úÖ All Prophet models loaded.\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: temp_max\n",
      "   -> MAE: 2.14\n",
      "   -> RMSE: 2.83\n",
      "   -> R2: 0.87\n",
      "   -> SMAPE: 7.75\n",
      "   -> Mean_Error: -0.00\n",
      "   -> Training MAE: 2.27\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: temp_min\n",
      "   -> MAE: 1.57\n",
      "   -> RMSE: 2.04\n",
      "   -> R2: 0.88\n",
      "   -> SMAPE: 12.69\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 1.60\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: humidity_specific\n",
      "   -> MAE: 0.93\n",
      "   -> RMSE: 1.18\n",
      "   -> R2: 0.74\n",
      "   -> SMAPE: 12.30\n",
      "   -> Mean_Error: -0.00\n",
      "   -> Training MAE: 0.90\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: pressure\n",
      "   -> MAE: 0.21\n",
      "   -> RMSE: 0.28\n",
      "   -> R2: 0.64\n",
      "   -> SMAPE: 0.21\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 0.22\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: solar_radiation\n",
      "   -> MAE: 0.36\n",
      "   -> RMSE: 0.57\n",
      "   -> R2: 0.90\n",
      "   -> SMAPE: 6.95\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 0.36\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üõ†Ô∏è Building and training final rain prediction pipeline...\n",
      "   -> Fitting XGBoost pipeline... (This may take a moment)\n",
      "‚úÖ Pipeline trained and saved to pipeline_ensemble.pkl\n",
      "\n",
      "üìä Evaluating rain prediction (XGBoost) model on Test Set...\n",
      "   -> Best Threshold (for F1 Score): 0.3580\n",
      "   -> Accuracy:  0.8989\n",
      "   -> Precision: 0.5377\n",
      "   -> Recall:    0.4743\n",
      "   -> F1 Score:  0.5040\n",
      "   -> ROC AUC:   0.8178\n",
      "   -> Confusion Matrix:\n",
      " [[2590  135]\n",
      " [ 174  157]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "üéâ All models trained! Let's get a forecast.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the start date (YYYY-MM-DD):  2025-12-10\n",
      "Enter the number of days to forecast:  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîÆ Forecasting future weather conditions with Prophet...\n",
      "‚úÖ Weather forecast complete.\n",
      "\n",
      "--- ‚òî Rain Forecast ---\n",
      "            Prob. of No Rain (%)  Prob. of Rain (%)             Recommendation\n",
      "date                                                                          \n",
      "2025-12-10             83.540001          16.459999  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-12-11             80.570000          19.430000  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-12-12             81.220001          18.780001  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-12-13             68.879997          31.120001  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-12-14             46.040001          53.959999        Take an umbrella! ‚òî\n",
      "2025-12-15             38.669998          61.330002        Take an umbrella! ‚òî\n",
      "2025-12-16             36.849998          63.150002        Take an umbrella! ‚òî\n",
      "2025-12-17             54.880001          45.119999        Take an umbrella! ‚òî\n",
      "2025-12-18             71.550003          28.450001  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "2025-12-19             84.250000          15.750000  Enjoy the clear skies! ‚òÄÔ∏è\n",
      "\n",
      "--- üå°Ô∏è Detailed Weather Forecast ---\n",
      "            temp_max  temp_min  humidity_specific  pressure  solar_radiation\n",
      "date                                                                        \n",
      "2025-12-10     21.99     10.70               6.92    100.25             3.54\n",
      "2025-12-11     21.84     10.56               6.89    100.25             3.53\n",
      "2025-12-12     21.69     10.42               6.86    100.26             3.52\n",
      "2025-12-13     21.55     10.29               6.83    100.26             3.51\n",
      "2025-12-14     21.41     10.15               6.80    100.27             3.50\n",
      "2025-12-15     21.28     10.02               6.77    100.27             3.50\n",
      "2025-12-16     21.14      9.89               6.75    100.28             3.49\n",
      "2025-12-17     21.02      9.76               6.72    100.28             3.49\n",
      "2025-12-18     20.90      9.63               6.70    100.28             3.49\n",
      "2025-12-19     20.78      9.51               6.67    100.28             3.48\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script performs a complete weather and rain forecasting workflow:\n",
    "1.  **GLDASFetcher**: Fetches historical weather data from the NASA POWER API\n",
    "    for a user-specified location.\n",
    "2.  **WeatherForecaster**:\n",
    "    a.  Cleans and prepares the fetched data.\n",
    "    b.  Trains a separate Facebook Prophet model for each weather variable\n",
    "        (e.g., temp, humidity) to learn its seasonal patterns.\n",
    "    c.  Saves these Prophet models to disk.\n",
    "    d.  Builds a complex scikit-learn pipeline that:\n",
    "        i.   Uses the trained Prophet models as feature generators.\n",
    "        ii.  Uses the raw (now forecasted) weather data as another set of features.\n",
    "        iii. Feeds both sets of features into an XGBoostClassifier to predict\n",
    "             the *probability of rain*.\n",
    "    e.  Evaluates all models (Prophet regression models and the final XGBoost\n",
    "        classification model).\n",
    "    f.  Provides a `model()` method that takes a future date and interval,\n",
    "        generates a full weather forecast, and predicts the likelihood of rain\n",
    "        for each day.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import requests\n",
    "import time\n",
    "import pickle as pk\n",
    "import joblib  \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "\n",
    "# Suppress a specific warning from sklearn about unfitted pipelines\n",
    "warnings.filterwarnings(\"ignore\", message=\"This Pipeline instance is not fitted yet\")\n",
    "\n",
    "\n",
    "# === PART 1: DATA FETCHING ===\n",
    "\n",
    "class GLDASFetcher:\n",
    "    \"\"\"\n",
    "    Handles fetching of daily weather data from the NASA POWER API.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NASA POWER API fetcher.\n",
    "        \"\"\"\n",
    "        # NASA POWER API is free and doesn't require credentials\n",
    "        \n",
    "        # Map our desired simple names to the NASA POWER API parameter codes\n",
    "        self.variables_map = {\n",
    "            'temp': ['T2M_MAX', 'T2M_MIN'],       # Daily max/min temp at 2m\n",
    "            'humidity': ['QV2M'],                 # Specific humidity at 2m\n",
    "            'pressure': ['PS'],                   # Surface pressure\n",
    "            'precipitation': ['PRECTOTCORR'],     # Corrected daily precipitation\n",
    "            'solar_rad': ['ALLSKY_SFC_SW_DWN'],   # All-sky surface shortwave downward radiation\n",
    "            'wind_speed': ['WS2M']                # Wind speed at 2m\n",
    "        }\n",
    "        \n",
    "        # Create a reverse map to rename API columns to friendly names\n",
    "        self.api_to_friendly_map = {\n",
    "            'T2M_MAX': 'temp_max',\n",
    "            'T2M_MIN': 'temp_min',\n",
    "            'QV2M': 'humidity_specific',\n",
    "            'PS': 'pressure',\n",
    "            'PRECTOTCORR': 'precipitation_total',\n",
    "            'ALLSKY_SFC_SW_DWN': 'solar_radiation',\n",
    "            'WS2M': 'wind_speed',\n",
    "            'latitude': 'lat',      # Will be added manually\n",
    "            'longitude': 'lon'      # Will be added manually\n",
    "        }\n",
    "\n",
    "    def get_data(self, lat, lon, start_date, end_date, variables=None):\n",
    "        \"\"\"\n",
    "        Fetch daily NASA POWER data for a single location and date range.\n",
    "\n",
    "        Args:\n",
    "            lat (float): Latitude\n",
    "            lon (float): Longitude\n",
    "            start_date (str): Start date \"YYYY-MM-DD\"\n",
    "            end_date (str): End date \"YYYY-MM-DD\"\n",
    "            variables (list, optional): List of keys from `self.variables_map`.\n",
    "                                        Defaults to all.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the time-series weather data,\n",
    "                          or an empty DataFrame if the API call fails.\n",
    "        \"\"\"\n",
    "        if variables is None:\n",
    "            variables = list(self.variables_map.keys())\n",
    "    \n",
    "        base_url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    \n",
    "        # Collect all required NASA POWER parameter codes\n",
    "        power_params = []\n",
    "        for var in variables:\n",
    "            power_params.extend(self.variables_map.get(var, []))\n",
    "    \n",
    "        params = {\n",
    "            'parameters': ','.join(power_params),\n",
    "            'community': 'RE',  # Renewable Energy community\n",
    "            'longitude': lon,\n",
    "            'latitude': lat,\n",
    "            'start': start_date.replace(\"-\", \"\"),  # API needs YYYYMMDD\n",
    "            'end': end_date.replace(\"-\", \"\"),\n",
    "            'format': 'JSON'\n",
    "        }\n",
    "    \n",
    "        print(f\"üåç Fetching NASA POWER data for ({lat}, {lon}) from {start_date} to {end_date} ...\")\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, timeout=60)\n",
    "            \n",
    "            # Check for HTTP errors\n",
    "            response.raise_for_status() \n",
    "    \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"‚ùå HTTP Error: {e}\")\n",
    "            print(f\"   Response content: {response.text}\")\n",
    "            return pd.DataFrame()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå API error (e.g., timeout, connection issue): {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Process the JSON response\n",
    "        try:\n",
    "            data = response.json()['properties']['parameter']\n",
    "        except KeyError:\n",
    "            print(\"‚ùå API Error: Unexpected JSON structure. 'properties' or 'parameter' key not found.\")\n",
    "            print(f\"   Response: {response.json()}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Build dataframe manually from the nested JSON\n",
    "        records = {}\n",
    "        for var_code, timeseries in data.items():\n",
    "            for date_str, value in timeseries.items():\n",
    "                # NASA POWER uses -999 as a fill value for missing data\n",
    "                value = np.nan if value == -999 else value\n",
    "                \n",
    "                if date_str not in records:\n",
    "                    records[date_str] = {}\n",
    "                records[date_str][var_code] = value\n",
    "    \n",
    "        if not records:\n",
    "            print(\"‚ùå No data records found in response.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Convert the dictionary of records into a DataFrame\n",
    "        df = pd.DataFrame.from_dict(records, orient='index')\n",
    "        df.index = pd.to_datetime(df.index, format=\"%Y%m%d\")\n",
    "        df.index.name = \"date\"\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        # Add metadata\n",
    "        df['latitude'] = lat\n",
    "        df['longitude'] = lon\n",
    "\n",
    "        # Rename columns from API codes to friendly names\n",
    "        df.rename(columns=self.api_to_friendly_map, inplace=True)\n",
    "        \n",
    "        # Ensure all expected columns exist, even if data was missing\n",
    "        expected_cols = ['date', 'lat', 'lon'] + [self.api_to_friendly_map[p] for p in power_params]\n",
    "        for col in expected_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = np.nan\n",
    "\n",
    "        print(f\"‚úÖ Retrieved {len(df)} daily records\")\n",
    "        return df\n",
    "\n",
    "    def get_location_by_address(self, address):\n",
    "        \"\"\"\n",
    "        Get latitude and longitude from a string address using Nominatim.\n",
    "        Retries recursively on failure.\n",
    "\n",
    "        Args:\n",
    "            address (str): The address to geocode (e.g., \"Paris, France\").\n",
    "\n",
    "        Returns:\n",
    "            dict: The raw location data from geopy, or None if it fails.\n",
    "        \"\"\"\n",
    "        time.sleep(1) \n",
    "        geolocator = Nominatim(user_agent=\"gldas_fetcher\")\n",
    "        try:\n",
    "            return geolocator.geocode(address).raw\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Geocoding failed ({e}). Retrying...\")\n",
    "            return self.get_location_by_address(address)  # Recursive retry\n",
    "\n",
    "\n",
    "# === PART 2: WEATHER & RAIN FORECASTING ===\n",
    "\n",
    "class WeatherForecaster:\n",
    "    \"\"\"\n",
    "    Handles training and prediction for weather variables (Prophet) and\n",
    "    rain probability (XGBoost).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, pipeline_path=\"pipeline_ensemble.pkl\"):\n",
    "        \"\"\"\n",
    "        Initialize the forecaster.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): Path to the CSV file with weather data.\n",
    "            pipeline_path (str, optional): Path to save/load the final\n",
    "                                           XGBoost pipeline.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.pipeline_path = pipeline_path\n",
    "        \n",
    "        # Load and clean the main dataset\n",
    "        self.df = self._load_and_clean_data(self.data_path)\n",
    "        \n",
    "        # Define the target variables for Prophet (all columns except metadata)\n",
    "        self.targets = self.df.columns.drop([\"date\", \"day_of_year\", \"lat\", \"lon\", \"did_rain\"])\n",
    "        \n",
    "        # Placeholders for models\n",
    "        self.models = None  # Will hold the loaded Prophet models\n",
    "        self.pipeline = None  # Will hold the loaded XGBoost pipeline\n",
    "        self.best_threshold = None # Optimal threshold for rain classification\n",
    "\n",
    "    def _load_and_clean_data(self, path):\n",
    "        \"\"\"\n",
    "        Loads the CSV, performs cleaning, and engineers features.\n",
    "        This is the base dataset for all models.\n",
    "        \"\"\"\n",
    "        print(f\"\\nüßπ Loading and cleaning data from {path}...\")\n",
    "        df = pd.read_csv(path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Feature Engineering\n",
    "        df['day_of_year'] = df['date'].dt.dayofyear\n",
    "        \n",
    "        # Create the binary target variable 'did_rain'\n",
    "        # (0.2 mm is a common threshold for \"trace\" precipitation)\n",
    "        df['did_rain'] = (df['precipitation_total'] >= 0.2).astype(int)\n",
    "        \n",
    "        # Replace NASA's fill value (-999) with NaN, just in case\n",
    "        df.replace(-999.0000, np.nan, inplace=True)\n",
    "        \n",
    "        # We drop 'precipitation_total' as it's the basis for our target\n",
    "        # 'wind_speed' is dropped here as it was likely found to be 'noise'\n",
    "        # during original model development.\n",
    "        df.drop(columns=[\"wind_speed\", \"precipitation_total\"], inplace=True)\n",
    "        \n",
    "        # Drop any rows with missing data to ensure model stability\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"‚úÖ Data cleaning complete.\")\n",
    "        return df\n",
    "\n",
    "    def _prepare_prophet_df(self, target_column):\n",
    "        \"\"\"\n",
    "        Extracts and renames the 'date' and a target column\n",
    "        from the main DataFrame, preparing it for Prophet.\n",
    "        \"\"\"\n",
    "        # Select the date and the specific target variable\n",
    "        df_prophet = self.df[['date', target_column]].copy()\n",
    "        \n",
    "        # Prophet requires columns to be named 'ds' (date) and 'y' (target)\n",
    "        df_prophet.rename(columns={'date': 'ds', target_column: 'y'}, inplace=True)\n",
    "        \n",
    "        return df_prophet\n",
    "\n",
    "    def train_and_save_prophet(self):\n",
    "        \"\"\"\n",
    "        Trains one Prophet model for each target variable in `self.targets`\n",
    "        and saves it to a .pkl file.\n",
    "        \"\"\"\n",
    "        print(\"\\nüöÇ Training Prophet models for each weather variable...\")\n",
    "        for target in self.targets:\n",
    "            # Get the formatted data for this target\n",
    "            df_prophet = self._prepare_prophet_df(target)\n",
    "            \n",
    "            # Initialize Prophet model\n",
    "            # We only care about the yearly pattern\n",
    "            model = Prophet(\n",
    "                yearly_seasonality=True,\n",
    "                weekly_seasonality=False,\n",
    "                daily_seasonality=False\n",
    "            )\n",
    "            \n",
    "            # Fit the model\n",
    "            model.fit(df_prophet)\n",
    "            \n",
    "            # Save the model\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            with open(filename, 'wb') as file:\n",
    "                pk.dump(model, file)\n",
    "            print(f\"   -> Model for '{target}' trained and saved to {filename}\")\n",
    "\n",
    "    def gathering_models(self):\n",
    "        \"\"\"\n",
    "        Loads all the pickled Prophet models from disk into `self.models`.\n",
    "        \"\"\"\n",
    "        print(\"\\nüì• Loading all trained Prophet models...\")\n",
    "        all_models = []\n",
    "        for target in self.targets:\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            try:\n",
    "                with open(filename, 'rb') as file:\n",
    "                    all_models.append(pk.load(file))\n",
    "                print(f\"   -> Loaded {filename}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"   -> ‚ùå ERROR: Model file not found: {filename}\")\n",
    "                print(\"   -> Please run `train_and_save_prophet()` first.\")\n",
    "                return None\n",
    "        \n",
    "        self.models = all_models\n",
    "        print(\"‚úÖ All Prophet models loaded.\")\n",
    "        return all_models\n",
    "\n",
    "    def predict_func(self, start_date, interval):\n",
    "        \"\"\"\n",
    "        Uses the loaded Prophet models to forecast all weather variables.\n",
    "\n",
    "        This function creates the *input features* that will be fed into\n",
    "        the final rain prediction (XGBoost) pipeline.\n",
    "\n",
    "        Args:\n",
    "            start_date (str): The starting date in 'YYYY-MM-DD' format.\n",
    "            interval (int): The number of future days to forecast.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the forecasted weather variables.\n",
    "        \"\"\"\n",
    "        # 1. Create a DataFrame with the future dates for Prophet\n",
    "        future_dates_df = pd.DataFrame({\n",
    "            'ds': pd.date_range(start=start_date, periods=interval, freq='D')\n",
    "        })\n",
    "\n",
    "        # 2. Start building the final DataFrame, beginning with the date column\n",
    "        future_weather_df = pd.DataFrame({'date': future_dates_df['ds']})\n",
    "\n",
    "        # 3. Loop through each Prophet model to forecast its specific weather variable\n",
    "        print(\"üîÆ Forecasting future weather conditions with Prophet...\")\n",
    "        \n",
    "        if not self.models:\n",
    "            print(\"‚ùå No Prophet models loaded. Running `gathering_models()`...\")\n",
    "            self.gathering_models()\n",
    "\n",
    "        # This assumes self.targets and self.models are in the same order\n",
    "        for target_variable, model in zip(self.targets, self.models):\n",
    "            # Use the model to predict values for the future dates\n",
    "            forecast = model.predict(future_dates_df)\n",
    "\n",
    "            # Extract the forecasted values ('yhat') and rename\n",
    "            future_values = forecast[['ds', 'yhat']].rename(\n",
    "                columns={'ds': 'date', 'yhat': target_variable}\n",
    "            )\n",
    "\n",
    "            # Merge this forecast into our main weather DataFrame\n",
    "            future_weather_df = pd.merge(future_weather_df, future_values, on='date')\n",
    "        \n",
    "        # 4. Ensure the column order matches exactly what the pipeline was trained on\n",
    "        #    This is the *input* format for the `save_pipeline` pipeline.\n",
    "        required_columns = ['date', 'temp_max', 'temp_min', 'humidity_specific', 'pressure', 'solar_radiation']\n",
    "        future_weather_df = future_weather_df[required_columns]\n",
    "\n",
    "        print(\"‚úÖ Weather forecast complete.\")\n",
    "        return future_weather_df\n",
    "\n",
    "    class ProphetWrapper(BaseEstimator, TransformerMixin):\n",
    "        \"\"\"\n",
    "        A custom wrapper to make a fitted Prophet model act like a\n",
    "        scikit-learn transformer, allowing it to be used in a Pipeline.\n",
    "        \"\"\"\n",
    "        def __init__(self, model):\n",
    "            self.model = model\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            # The model is already fitted, so fit does nothing\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            \"\"\"\n",
    "            `X` is expected to be a column of dates.\n",
    "            `transform` will return the 'yhat' (forecast) for those dates.\n",
    "            \"\"\"\n",
    "            # 1. Convert input (which is just a date series) into\n",
    "            #    the DataFrame format Prophet expects.\n",
    "            future = pd.DataFrame({'ds': X.flatten()})\n",
    "            \n",
    "            # 2. Make predictions\n",
    "            forecast = self.model.predict(future)\n",
    "            \n",
    "            # 3. Return *only* the 'yhat' value as a 2D array\n",
    "            return forecast[['yhat']].values\n",
    "\n",
    "    def save_pipeline(self):\n",
    "        \"\"\"\n",
    "        Builds, trains, and saves the final \"ensemble\" pipeline that\n",
    "        predicts rain using XGBoost.\n",
    "        \"\"\"\n",
    "        print(\"\\nüõ†Ô∏è Building and training final rain prediction pipeline...\")\n",
    "\n",
    "        # --- 1. Define Feature Sets ---\n",
    "        # The 'date' column will be used by the Prophet transformers\n",
    "        date_feature = ['date'] \n",
    "        # These columns will be used by the standard scaling pipeline\n",
    "        weather_features = ['temp_max', 'temp_min', 'humidity_specific', 'pressure', \"solar_radiation\"] \n",
    "        \n",
    "        # --- 2. Create the Prophet Forecasting Pipeline Branch ---\n",
    "        # This branch takes the 'date' column and, for each date,\n",
    "        # generates a *new* set of weather forecasts using Prophet.\n",
    "        \n",
    "        if not self.models:\n",
    "            print(\"‚ùå No Prophet models found. Running `gathering_models()`...\")\n",
    "            self.gathering_models()\n",
    "            \n",
    "        p_models = self.models\n",
    "        wrapped_prophets = [\n",
    "            (f'prophet_{target}', self.ProphetWrapper(model))\n",
    "            for target, model in zip(self.targets, p_models)\n",
    "        ]\n",
    "        \n",
    "        # Use FeatureUnion to run all Prophet models in parallel\n",
    "        prophet_forecasters = FeatureUnion(wrapped_prophets)\n",
    "        \n",
    "        # This pipeline selects *only* the 'date' column and passes it\n",
    "        # to the bank of Prophet forecasters.\n",
    "        prophet_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer(\n",
    "                [('date_selector', 'passthrough', [0])],  # Assumes 'date' is at index 0\n",
    "                remainder='drop'\n",
    "            )),\n",
    "            ('prophet_features', prophet_forecasters)\n",
    "        ])\n",
    "        \n",
    "        # --- 3. Create the Standard Weather Pipeline Branch ---\n",
    "        # This branch takes the *actual* weather features, scales them,\n",
    "        # and passes them through.\n",
    "        weather_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer(\n",
    "                # Select all columns that are in our 'weather_features' list\n",
    "                [('weather_selector', 'passthrough', [i for i, col in enumerate(self.df.drop(columns='did_rain').columns) if col in weather_features])],\n",
    "                remainder='drop'\n",
    "            )),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        # --- 4. Combine Both Branches ---\n",
    "        # The final feature set for XGBoost will be:\n",
    "        # [prophet_temp, prophet_hum, ..., scaled_actual_temp, scaled_actual_hum, ...]\n",
    "        combined_features = FeatureUnion([\n",
    "            ('prophet_pipeline', prophet_pipeline),\n",
    "            ('weather_pipeline', weather_pipeline)\n",
    "        ])\n",
    "        \n",
    "        # --- 5. Split Data for Training ---\n",
    "        X = self.df.drop(columns='did_rain')\n",
    "        y = self.df['did_rain'].values\n",
    "        \n",
    "        # We MUST set shuffle=False for time-series data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Calculate imbalance ratio for `scale_pos_weight`\n",
    "        # This helps the model pay more attention to the rare 'rain' class\n",
    "        neg, pos = np.bincount(y)\n",
    "        imbalance_ratio = neg / pos\n",
    "        \n",
    "        # --- 6. Create and Train the Final Pipeline ---\n",
    "        final_pipeline = Pipeline([\n",
    "            ('features', combined_features),\n",
    "            ('xgb_classifier', XGBClassifier(\n",
    "                n_estimators=550,\n",
    "                max_depth=8,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.7,\n",
    "                scale_pos_weight=imbalance_ratio,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        print(\"   -> Fitting XGBoost pipeline... (This may take a moment)\")\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained pipeline\n",
    "        joblib.dump(final_pipeline, self.pipeline_path)\n",
    "        print(f\"‚úÖ Pipeline trained and saved to {self.pipeline_path}\")\n",
    "\n",
    "        # --- 7. Evaluate the Pipeline ---\n",
    "        print(\"\\nüìä Evaluating rain prediction (XGBoost) model on Test Set...\")\n",
    "        y_pred_proba = final_pipeline.predict_proba(X_test)[:, 1] # Prob of '1' (rain)\n",
    "        \n",
    "        # Find the best threshold for F1-score\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "        \n",
    "        # Add a small epsilon (1e-9) to avoid division by zero\n",
    "        f1_scores = 2 * recall * precision / (recall + precision + 1e-9)\n",
    "        \n",
    "        # Find the threshold that gives the best F1 score\n",
    "        self.best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        \n",
    "        print(f\"   -> Best Threshold (for F1 Score): {self.best_threshold:.4f}\")\n",
    "        \n",
    "        # Apply the best threshold to get binary predictions\n",
    "        y_pred = (y_pred_proba >= self.best_threshold).astype(int)\n",
    "        \n",
    "        # Print classification metrics\n",
    "        print(f\"   -> Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> F1 Score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> ROC AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "        print(\"   -> Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    def calculate_metrics(self, test, train, model):\n",
    "        \"\"\"\n",
    "        Helper function to calculate regression metrics for Prophet models.\n",
    "        \"\"\"\n",
    "        # Get predictions\n",
    "        train_pred = model.predict(train)\n",
    "        test_pred = model.predict(test)\n",
    "    \n",
    "        y_true = test['y'].values\n",
    "        y_pred = test_pred['yhat'].values\n",
    "    \n",
    "        y_train = train['y'].values\n",
    "        yhat_train = train_pred['yhat'].values\n",
    "    \n",
    "        # Symmetric Mean Absolute Percentage Error\n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "    \n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'R2': r2_score(y_true, y_pred),\n",
    "            \"SMAPE\": smape,\n",
    "            'Mean_Error': np.mean(y_pred - y_true),  # Bias\n",
    "            'Training MAE': mean_absolute_error(y_train, yhat_train)\n",
    "        }\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"   -> {metric}: {value:.2f}\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Main user-facing function to generate a complete forecast.\n",
    "        \n",
    "        Prompts the user for a start date and interval, then returns\n",
    "        the rain probability and the detailed weather forecast.\n",
    "\n",
    "        Returns:\n",
    "            (pd.DataFrame, pd.DataFrame):\n",
    "                - proba_df: DataFrame with rain probabilities and recommendations.\n",
    "                - weather_preds_df: DataFrame with detailed weather forecasts.\n",
    "        \"\"\"\n",
    "        # 1. Load the main rain prediction pipeline\n",
    "        try:\n",
    "            self.pipeline = joblib.load(self.pipeline_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Pipeline file not found at {self.pipeline_path}.\")\n",
    "            print(\"   -> Please run `save_pipeline()` first.\")\n",
    "            return None, None\n",
    "        \n",
    "        # 2. Get the date and interval from the user\n",
    "        start_date = input(\"\\nEnter the start date (YYYY-MM-DD): \")\n",
    "        interval = int(input(\"Enter the number of days to forecast: \"))\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 3. Call the helper function to get the weather forecast for the full interval.\n",
    "        #    This `weather_preds_df` contains all the features needed for the next step.\n",
    "        weather_preds_df = self.predict_func(start_date, interval)\n",
    "\n",
    "        # 4. Use the complete weather forecast to predict the probability of rain.\n",
    "        #    The pipeline receives a DataFrame with multiple rows and 6 columns, just as it expects.\n",
    "        rain_probabilities = self.pipeline.predict_proba(weather_preds_df)\n",
    "\n",
    "        # 5. Format the rain probability results into a clean DataFrame\n",
    "        proba_df = pd.DataFrame(\n",
    "            (rain_probabilities * 100).round(2),\n",
    "            columns=[\"Prob. of No Rain (%)\", \"Prob. of Rain (%)\"],\n",
    "            index=weather_preds_df['date']  # Use the future dates as the index\n",
    "        )\n",
    "        \n",
    "        # 6. Add a human-readable recommendation\n",
    "        #    (Use a default threshold if `save_pipeline` hasn't been run)\n",
    "        best_threshold_percent = (self.best_threshold or 0.5) * 100\n",
    "        \n",
    "        proba_df[\"Recommendation\"] = proba_df['Prob. of Rain (%)'].apply(\n",
    "            lambda x: \"Take an umbrella! ‚òî\" if x >= best_threshold_percent else \"Enjoy the clear skies! ‚òÄÔ∏è\")\n",
    "        \n",
    "\n",
    "        # 7. Return both the rain probabilities and the detailed weather predictions\n",
    "        return proba_df, weather_preds_df.set_index('date')\n",
    "    \n",
    "    def prophet_metrics(self):\n",
    "        \"\"\"\n",
    "        Calculates and prints regression metrics for all the\n",
    "        individual Prophet models.\n",
    "        \"\"\"\n",
    "        print(\"\\nüìà Evaluating individual Prophet (weather) models...\")\n",
    "        \n",
    "        models = self.gathering_models()\n",
    "        if not models:\n",
    "            return\n",
    "\n",
    "        for i, target in enumerate(self.targets):\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"Evaluation Results for: {target}\")\n",
    "            \n",
    "            # Get the data for this target\n",
    "            df_prophet = self._prepare_prophet_df(target)\n",
    "            \n",
    "            # Split the data (must be same split as XGBoost)\n",
    "            train_df, test_df = train_test_split(df_prophet, test_size=0.2, shuffle=False)\n",
    "            \n",
    "            # Calculate and print metrics\n",
    "            self.calculate_metrics(test_df, train_df, models[i])\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "\n",
    "# === PART 3: SCRIPT EXECUTION ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- Phase 1: Fetch Data ---\n",
    "    print(\"üöÄ NASA GLDAS Data Fetcher & Rain Forecaster\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize the fetcher\n",
    "    fetcher = GLDASFetcher()\n",
    "    city = input(\"Enter the city name (e.g., 'Cairo, Egypt'): \")\n",
    "    \n",
    "    location = fetcher.get_location_by_address(city)\n",
    "    lat = location[\"lat\"]\n",
    "    lon = location[\"lon\"]\n",
    "    city_name = location['display_name']\n",
    "\n",
    "    print(f\"\\nGeocoded {city} to: {city_name} ({lat}, {lon})\")\n",
    "    \n",
    "    # Define a long historical period for robust model training\n",
    "    start_date = \"1984-01-01\"\n",
    "    # Fetch data up to yesterday\n",
    "    end_date = (datetime.now() - timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    \n",
    "    data = fetcher.get_data(\n",
    "        lat=lat,\n",
    "        lon=lon,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        variables=['temp', 'humidity', 'pressure', 'precipitation', 'solar_rad', 'wind_speed']\n",
    "    )\n",
    "    \n",
    "    if data.empty:\n",
    "        print(\"‚ùå No data retrieved. Exiting script.\")\n",
    "    else:\n",
    "        # Save the data to a CSV file\n",
    "        data_path = \"nasa_daily_weather_data.csv\"\n",
    "        data.to_csv(data_path, index=False)\n",
    "        print(f\"\\n‚úÖ Data successfully saved to {data_path}\")\n",
    "        \n",
    "        # --- Phase 2: Train and Run Forecaster ---\n",
    "        \n",
    "        # Initialize the forecaster with the data we just saved\n",
    "        wf = WeatherForecaster(data_path=data_path)\n",
    "        \n",
    "        # 1. Train and save all the Prophet models (temp, humidity, etc.)\n",
    "        wf.train_and_save_prophet()\n",
    "        \n",
    "        # 2. Evaluate the Prophet models\n",
    "        wf.prophet_metrics()\n",
    "        \n",
    "        # 3. Train and save the main XGBoost rain prediction pipeline\n",
    "        wf.save_pipeline()\n",
    "        \n",
    "        # --- Phase 3: Get a Forecast ---\n",
    "        print(\"\\n\\n\" + \"=\" * 50)\n",
    "        print(\"üéâ All models trained! Let's get a forecast.\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 4. Run the main model function\n",
    "        rain_forecast, weather_forecast = wf.model()\n",
    "        \n",
    "        if rain_forecast is not None:\n",
    "            print(\"\\n--- ‚òî Rain Forecast ---\")\n",
    "            print(rain_forecast)\n",
    "            \n",
    "            print(\"\\n--- üå°Ô∏è Detailed Weather Forecast ---\")\n",
    "            print(weather_forecast.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0656b19-8d45-481b-97bd-f7499e262aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_max</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>humidity_specific</th>\n",
       "      <th>pressure</th>\n",
       "      <th>solar_radiation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-12-10</th>\n",
       "      <td>21.992522</td>\n",
       "      <td>10.703170</td>\n",
       "      <td>6.919742</td>\n",
       "      <td>100.248645</td>\n",
       "      <td>3.540198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-11</th>\n",
       "      <td>21.841458</td>\n",
       "      <td>10.563173</td>\n",
       "      <td>6.887751</td>\n",
       "      <td>100.253842</td>\n",
       "      <td>3.529355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-12</th>\n",
       "      <td>21.694178</td>\n",
       "      <td>10.424236</td>\n",
       "      <td>6.857209</td>\n",
       "      <td>100.258735</td>\n",
       "      <td>3.519805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-13</th>\n",
       "      <td>21.550770</td>\n",
       "      <td>10.286720</td>\n",
       "      <td>6.827947</td>\n",
       "      <td>100.263317</td>\n",
       "      <td>3.511488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-14</th>\n",
       "      <td>21.411326</td>\n",
       "      <td>10.150999</td>\n",
       "      <td>6.799797</td>\n",
       "      <td>100.267586</td>\n",
       "      <td>3.504342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-15</th>\n",
       "      <td>21.275946</td>\n",
       "      <td>10.017456</td>\n",
       "      <td>6.772589</td>\n",
       "      <td>100.271545</td>\n",
       "      <td>3.498294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-16</th>\n",
       "      <td>21.144749</td>\n",
       "      <td>9.886478</td>\n",
       "      <td>6.746162</td>\n",
       "      <td>100.275201</td>\n",
       "      <td>3.493271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>21.017870</td>\n",
       "      <td>9.758452</td>\n",
       "      <td>6.720363</td>\n",
       "      <td>100.278565</td>\n",
       "      <td>3.489202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>20.895467</td>\n",
       "      <td>9.633759</td>\n",
       "      <td>6.695048</td>\n",
       "      <td>100.281654</td>\n",
       "      <td>3.486015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-19</th>\n",
       "      <td>20.777723</td>\n",
       "      <td>9.512769</td>\n",
       "      <td>6.670090</td>\n",
       "      <td>100.284487</td>\n",
       "      <td>3.483645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             temp_max   temp_min  humidity_specific    pressure  \\\n",
       "date                                                              \n",
       "2025-12-10  21.992522  10.703170           6.919742  100.248645   \n",
       "2025-12-11  21.841458  10.563173           6.887751  100.253842   \n",
       "2025-12-12  21.694178  10.424236           6.857209  100.258735   \n",
       "2025-12-13  21.550770  10.286720           6.827947  100.263317   \n",
       "2025-12-14  21.411326  10.150999           6.799797  100.267586   \n",
       "2025-12-15  21.275946  10.017456           6.772589  100.271545   \n",
       "2025-12-16  21.144749   9.886478           6.746162  100.275201   \n",
       "2025-12-17  21.017870   9.758452           6.720363  100.278565   \n",
       "2025-12-18  20.895467   9.633759           6.695048  100.281654   \n",
       "2025-12-19  20.777723   9.512769           6.670090  100.284487   \n",
       "\n",
       "            solar_radiation  \n",
       "date                         \n",
       "2025-12-10         3.540198  \n",
       "2025-12-11         3.529355  \n",
       "2025-12-12         3.519805  \n",
       "2025-12-13         3.511488  \n",
       "2025-12-14         3.504342  \n",
       "2025-12-15         3.498294  \n",
       "2025-12-16         3.493271  \n",
       "2025-12-17         3.489202  \n",
       "2025-12-18         3.486015  \n",
       "2025-12-19         3.483645  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebba56f6-7a02-4095-a406-582b5665498c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob. of No Rain (%)</th>\n",
       "      <th>Prob. of Rain (%)</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-12-10</th>\n",
       "      <td>83.540001</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-11</th>\n",
       "      <td>80.570000</td>\n",
       "      <td>19.430000</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-12</th>\n",
       "      <td>81.220001</td>\n",
       "      <td>18.780001</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-13</th>\n",
       "      <td>68.879997</td>\n",
       "      <td>31.120001</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-14</th>\n",
       "      <td>46.040001</td>\n",
       "      <td>53.959999</td>\n",
       "      <td>Take an umbrella! ‚òî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-15</th>\n",
       "      <td>38.669998</td>\n",
       "      <td>61.330002</td>\n",
       "      <td>Take an umbrella! ‚òî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-16</th>\n",
       "      <td>36.849998</td>\n",
       "      <td>63.150002</td>\n",
       "      <td>Take an umbrella! ‚òî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-17</th>\n",
       "      <td>54.880001</td>\n",
       "      <td>45.119999</td>\n",
       "      <td>Take an umbrella! ‚òî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-18</th>\n",
       "      <td>71.550003</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-19</th>\n",
       "      <td>84.250000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>Enjoy the clear skies! ‚òÄÔ∏è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prob. of No Rain (%)  Prob. of Rain (%)             Recommendation\n",
       "date                                                                          \n",
       "2025-12-10             83.540001          16.459999  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-12-11             80.570000          19.430000  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-12-12             81.220001          18.780001  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-12-13             68.879997          31.120001  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-12-14             46.040001          53.959999        Take an umbrella! ‚òî\n",
       "2025-12-15             38.669998          61.330002        Take an umbrella! ‚òî\n",
       "2025-12-16             36.849998          63.150002        Take an umbrella! ‚òî\n",
       "2025-12-17             54.880001          45.119999        Take an umbrella! ‚òî\n",
       "2025-12-18             71.550003          28.450001  Enjoy the clear skies! ‚òÄÔ∏è\n",
       "2025-12-19             84.250000          15.750000  Enjoy the clear skies! ‚òÄÔ∏è"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da42644-bc60-430e-9402-ec4c347c24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data successfully saved to nasa_daily_weather_data.csv\n",
      "\n",
      "üßπ Loading and cleaning data from nasa_daily_weather_data.csv...\n",
      "‚úÖ Data cleaning complete.\n",
      "\n",
      "üöÇ Training Prophet models for each weather variable...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:13:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:13:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'temp_max' trained and saved to prophet_model_temp_max.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:13:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:13:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'temp_min' trained and saved to prophet_model_temp_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:13:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:13:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'humidity_specific' trained and saved to prophet_model_humidity_specific.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:14:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:14:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'pressure' trained and saved to prophet_model_pressure.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:14:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:14:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'solar_radiation' trained and saved to prophet_model_solar_radiation.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:14:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:14:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'evapotranspiration' trained and saved to prophet_model_evapotranspiration.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:14:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:14:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'soil_moisture_surface' trained and saved to prophet_model_soil_moisture_surface.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:14:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:14:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> Model for 'dew_point_temp' trained and saved to prophet_model_dew_point_temp.pkl\n",
      "\n",
      "üìà Evaluating individual Prophet (weather) models...\n",
      "\n",
      "üì• Loading all trained Prophet models...\n",
      "   -> Loaded prophet_model_temp_max.pkl\n",
      "   -> Loaded prophet_model_temp_min.pkl\n",
      "   -> Loaded prophet_model_humidity_specific.pkl\n",
      "   -> Loaded prophet_model_pressure.pkl\n",
      "   -> Loaded prophet_model_solar_radiation.pkl\n",
      "   -> Loaded prophet_model_evapotranspiration.pkl\n",
      "   -> Loaded prophet_model_soil_moisture_surface.pkl\n",
      "   -> Loaded prophet_model_dew_point_temp.pkl\n",
      "‚úÖ All Prophet models loaded.\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: temp_max\n",
      "   -> MAE: 2.14\n",
      "   -> RMSE: 2.83\n",
      "   -> R2: 0.87\n",
      "   -> SMAPE: 7.75\n",
      "   -> Mean_Error: -0.00\n",
      "   -> Training MAE: 2.27\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: temp_min\n",
      "   -> MAE: 1.57\n",
      "   -> RMSE: 2.04\n",
      "   -> R2: 0.88\n",
      "   -> SMAPE: 12.69\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 1.60\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: humidity_specific\n",
      "   -> MAE: 0.93\n",
      "   -> RMSE: 1.18\n",
      "   -> R2: 0.74\n",
      "   -> SMAPE: 12.30\n",
      "   -> Mean_Error: -0.00\n",
      "   -> Training MAE: 0.90\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: pressure\n",
      "   -> MAE: 0.21\n",
      "   -> RMSE: 0.28\n",
      "   -> R2: 0.64\n",
      "   -> SMAPE: 0.21\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 0.22\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: solar_radiation\n",
      "   -> MAE: 1.29\n",
      "   -> RMSE: 2.04\n",
      "   -> R2: 0.90\n",
      "   -> SMAPE: 6.95\n",
      "   -> Mean_Error: 0.01\n",
      "   -> Training MAE: 1.31\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: evapotranspiration\n",
      "   -> MAE: 0.02\n",
      "   -> RMSE: 0.04\n",
      "   -> R2: 0.07\n",
      "   -> SMAPE: 165.23\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 0.00\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: soil_moisture_surface\n",
      "   -> MAE: 0.07\n",
      "   -> RMSE: 0.09\n",
      "   -> R2: 0.59\n",
      "   -> SMAPE: 33.96\n",
      "   -> Mean_Error: 0.00\n",
      "   -> Training MAE: 0.04\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Evaluation Results for: dew_point_temp\n",
      "   -> MAE: 1.87\n",
      "   -> RMSE: 2.44\n",
      "   -> R2: 0.69\n",
      "   -> SMAPE: 25.48\n",
      "   -> Mean_Error: -0.01\n",
      "   -> Training MAE: 2.03\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üõ†Ô∏è Building and training final rain prediction pipeline...\n",
      "   -> Fitting XGBoost pipeline... (This may take a moment)\n",
      "‚úÖ Pipeline trained and saved to pipeline_ensemble.pkl\n",
      "\n",
      "üìä Evaluating rain prediction (XGBoost) model on Test Set...\n",
      "   -> Best Threshold (for F1 Score): 0.2457\n",
      "   -> Accuracy:  0.8740\n",
      "   -> Precision: 0.4381\n",
      "   -> Recall:    0.5770\n",
      "   -> F1 Score:  0.4980\n",
      "   -> ROC AUC:   0.8224\n",
      "   -> Confusion Matrix:\n",
      " [[2480  245]\n",
      " [ 140  191]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "üéâ All models trained! Let's get a forecast.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# === PART 2: WEATHER & RAIN FORECASTING ===\n",
    "\n",
    "class WeatherForecaster:\n",
    "    \"\"\"\n",
    "    Handles training and prediction for weather variables (Prophet) and\n",
    "    rain probability (XGBoost).\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, pipeline_path=\"pipeline_ensemble.pkl\"):\n",
    "        \"\"\"\n",
    "        Initialize the forecaster.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): Path to the CSV file with weather data.\n",
    "            pipeline_path (str, optional): Path to save/load the final\n",
    "                                           XGBoost pipeline.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.pipeline_path = pipeline_path\n",
    "        \n",
    "        # Load and clean the main dataset\n",
    "        self.df = self._load_and_clean_data(self.data_path)\n",
    "        \n",
    "        # Define the target variables for Prophet (all columns except metadata)\n",
    "        self.targets = self.df.columns.drop([\"date\", \"day_of_year\", \"lat\", \"lon\", \"did_rain\"])\n",
    "        \n",
    "        # Placeholders for models\n",
    "        self.models = None  # Will hold the loaded Prophet models\n",
    "        self.pipeline = None  # Will hold the loaded XGBoost pipeline\n",
    "        self.best_threshold = None # Optimal threshold for rain classification\n",
    "\n",
    "    def _load_and_clean_data(self, path):\n",
    "        \"\"\"\n",
    "        Loads the CSV, performs cleaning, and engineers features.\n",
    "        This is the base dataset for all models.\n",
    "        \"\"\"\n",
    "        print(f\"\\nüßπ Loading and cleaning data from {path}...\")\n",
    "        df = pd.read_csv(path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Feature Engineering\n",
    "        df['day_of_year'] = df['date'].dt.dayofyear\n",
    "        \n",
    "        # Create the binary target variable 'did_rain'\n",
    "        # (0.2 mm is a common threshold for \"trace\" precipitation)\n",
    "        df['did_rain'] = (df['precipitation_total'] >= 0.2).astype(int)\n",
    "        \n",
    "        # Replace NASA's fill value (-999) with NaN, just in case\n",
    "        df.replace(-999.0000, np.nan, inplace=True)\n",
    "        \n",
    "        # We drop 'precipitation_total' as it's the basis for our target\n",
    "        # 'wind_speed' is dropped here as it was likely found to be 'noise'\n",
    "        # during original model development.\n",
    "        df.drop(columns=[\"precipitation_total\"], inplace=True)\n",
    "        \n",
    "        # Drop any rows with missing data to ensure model stability\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"‚úÖ Data cleaning complete.\")\n",
    "        return df\n",
    "\n",
    "    def _prepare_prophet_df(self, target_column):\n",
    "        \"\"\"\n",
    "        Extracts and renames the 'date' and a target column\n",
    "        from the main DataFrame, preparing it for Prophet.\n",
    "        \"\"\"\n",
    "        # Select the date and the specific target variable\n",
    "        df_prophet = self.df[['date', target_column]].copy()\n",
    "        \n",
    "        # Prophet requires columns to be named 'ds' (date) and 'y' (target)\n",
    "        df_prophet.rename(columns={'date': 'ds', target_column: 'y'}, inplace=True)\n",
    "        \n",
    "        return df_prophet\n",
    "\n",
    "    def train_and_save_prophet(self):\n",
    "        \"\"\"\n",
    "        Trains one Prophet model for each target variable in `self.targets`\n",
    "        and saves it to a .pkl file.\n",
    "        \"\"\"\n",
    "        print(\"\\nüöÇ Training Prophet models for each weather variable...\")\n",
    "        for target in self.targets:\n",
    "            # Get the formatted data for this target\n",
    "            df_prophet = self._prepare_prophet_df(target)\n",
    "            \n",
    "            # Initialize Prophet model\n",
    "            # We only care about the yearly pattern\n",
    "            model = Prophet(\n",
    "                yearly_seasonality=True,\n",
    "                weekly_seasonality=False,\n",
    "                daily_seasonality=False\n",
    "            )\n",
    "            \n",
    "            # Fit the model\n",
    "            model.fit(df_prophet)\n",
    "            \n",
    "            # Save the model\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            with open(filename, 'wb') as file:\n",
    "                pk.dump(model, file)\n",
    "            print(f\"   -> Model for '{target}' trained and saved to {filename}\")\n",
    "\n",
    "    def gathering_models(self):\n",
    "        \"\"\"\n",
    "        Loads all the pickled Prophet models from disk into `self.models`.\n",
    "        \"\"\"\n",
    "        print(\"\\nüì• Loading all trained Prophet models...\")\n",
    "        all_models = []\n",
    "        for target in self.targets:\n",
    "            filename = f'prophet_model_{target}.pkl'\n",
    "            try:\n",
    "                with open(filename, 'rb') as file:\n",
    "                    all_models.append(pk.load(file))\n",
    "                print(f\"   -> Loaded {filename}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"   -> ‚ùå ERROR: Model file not found: {filename}\")\n",
    "                print(\"   -> Please run `train_and_save_prophet()` first.\")\n",
    "                return None\n",
    "        \n",
    "        self.models = all_models\n",
    "        print(\"‚úÖ All Prophet models loaded.\")\n",
    "        return all_models\n",
    "\n",
    "    def predict_func(self, start_date, interval):\n",
    "        \"\"\"\n",
    "        Uses the loaded Prophet models to forecast all weather variables.\n",
    "\n",
    "        This function creates the *input features* that will be fed into\n",
    "        the final rain prediction (XGBoost) pipeline.\n",
    "\n",
    "        Args:\n",
    "            start_date (str): The starting date in 'YYYY-MM-DD' format.\n",
    "            interval (int): The number of future days to forecast.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the forecasted weather variables.\n",
    "        \"\"\"\n",
    "        # 1. Create a DataFrame with the future dates for Prophet\n",
    "        future_dates_df = pd.DataFrame({\n",
    "            'ds': pd.date_range(start=start_date, periods=interval, freq='D')\n",
    "        })\n",
    "\n",
    "        # 2. Start building the final DataFrame, beginning with the date column\n",
    "        future_weather_df = pd.DataFrame({'date': future_dates_df['ds']})\n",
    "\n",
    "        # 3. Loop through each Prophet model to forecast its specific weather variable\n",
    "        print(\"üîÆ Forecasting future weather conditions with Prophet...\")\n",
    "        \n",
    "        if not self.models:\n",
    "            print(\"‚ùå No Prophet models loaded. Running `gathering_models()`...\")\n",
    "            self.gathering_models()\n",
    "\n",
    "        # This assumes self.targets and self.models are in the same order\n",
    "        for target_variable, model in zip(self.targets, self.models):\n",
    "            # Use the model to predict values for the future dates\n",
    "            forecast = model.predict(future_dates_df)\n",
    "\n",
    "            # Extract the forecasted values ('yhat') and rename\n",
    "            future_values = forecast[['ds', 'yhat']].rename(\n",
    "                columns={'ds': 'date', 'yhat': target_variable}\n",
    "            )\n",
    "\n",
    "            # Merge this forecast into our main weather DataFrame\n",
    "            future_weather_df = pd.merge(future_weather_df, future_values, on='date')\n",
    "        \n",
    "        # 4. Ensure the column order matches exactly what the pipeline was trained on\n",
    "        #    This is the *input* format for the `save_pipeline` pipeline.\n",
    "        required_columns = ['date', 'temp_max', 'temp_min', 'humidity_specific', 'pressure', 'solar_radiation',\"evapotranspiration\",\"soil_moisture_surface\",\"dew_point_temp\"]\n",
    "        future_weather_df = future_weather_df[required_columns]\n",
    "\n",
    "        print(\"‚úÖ Weather forecast complete.\")\n",
    "        return future_weather_df\n",
    "\n",
    "    class ProphetWrapper(BaseEstimator, TransformerMixin):\n",
    "        \"\"\"\n",
    "        A custom wrapper to make a fitted Prophet model act like a\n",
    "        scikit-learn transformer, allowing it to be used in a Pipeline.\n",
    "        \"\"\"\n",
    "        def __init__(self, model):\n",
    "            self.model = model\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            # The model is already fitted, so fit does nothing\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            \"\"\"\n",
    "            `X` is expected to be a column of dates.\n",
    "            `transform` will return the 'yhat' (forecast) for those dates.\n",
    "            \"\"\"\n",
    "            # 1. Convert input (which is just a date series) into\n",
    "            #    the DataFrame format Prophet expects.\n",
    "            future = pd.DataFrame({'ds': X.flatten()})\n",
    "            \n",
    "            # 2. Make predictions\n",
    "            forecast = self.model.predict(future)\n",
    "            \n",
    "            # 3. Return *only* the 'yhat' value as a 2D array\n",
    "            return forecast[['yhat']].values\n",
    "\n",
    "    def save_pipeline(self):\n",
    "        \"\"\"\n",
    "        Builds, trains, and saves the final \"ensemble\" pipeline that\n",
    "        predicts rain using XGBoost.\n",
    "        \"\"\"\n",
    "        print(\"\\nüõ†Ô∏è Building and training final rain prediction pipeline...\")\n",
    "\n",
    "        # --- 1. Define Feature Sets ---\n",
    "        # The 'date' column will be used by the Prophet transformers\n",
    "        date_feature = ['date'] \n",
    "        # These columns will be used by the standard scaling pipeline\n",
    "        weather_features = ['temp_max', 'temp_min', 'humidity_specific', 'pressure', \"solar_radiation\"] \n",
    "        \n",
    "        # --- 2. Create the Prophet Forecasting Pipeline Branch ---\n",
    "        # This branch takes the 'date' column and, for each date,\n",
    "        # generates a *new* set of weather forecasts using Prophet.\n",
    "        \n",
    "        if not self.models:\n",
    "            print(\"‚ùå No Prophet models found. Running `gathering_models()`...\")\n",
    "            self.gathering_models()\n",
    "            \n",
    "        p_models = self.models\n",
    "        wrapped_prophets = [\n",
    "            (f'prophet_{target}', self.ProphetWrapper(model))\n",
    "            for target, model in zip(self.targets, p_models)\n",
    "        ]\n",
    "        \n",
    "        # Use FeatureUnion to run all Prophet models in parallel\n",
    "        prophet_forecasters = FeatureUnion(wrapped_prophets)\n",
    "        \n",
    "        # This pipeline selects *only* the 'date' column and passes it\n",
    "        # to the bank of Prophet forecasters.\n",
    "        prophet_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer(\n",
    "                [('date_selector', 'passthrough', [0])],  # Assumes 'date' is at index 0\n",
    "                remainder='drop'\n",
    "            )),\n",
    "            ('prophet_features', prophet_forecasters)\n",
    "        ])\n",
    "        \n",
    "        # --- 3. Create the Standard Weather Pipeline Branch ---\n",
    "        # This branch takes the *actual* weather features, scales them,\n",
    "        # and passes them through.\n",
    "        weather_pipeline = Pipeline([\n",
    "            ('selector', ColumnTransformer(\n",
    "                # Select all columns that are in our 'weather_features' list\n",
    "                [('weather_selector', 'passthrough', [i for i, col in enumerate(self.df.drop(columns='did_rain').columns) if col in weather_features])],\n",
    "                remainder='drop'\n",
    "            )),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        # --- 4. Combine Both Branches ---\n",
    "        # The final feature set for XGBoost will be:\n",
    "        # [prophet_temp, prophet_hum, ..., scaled_actual_temp, scaled_actual_hum, ...]\n",
    "        combined_features = FeatureUnion([\n",
    "            ('prophet_pipeline', prophet_pipeline),\n",
    "            ('weather_pipeline', weather_pipeline)\n",
    "        ])\n",
    "        \n",
    "        # --- 5. Split Data for Training ---\n",
    "        X = self.df.drop(columns='did_rain')\n",
    "        y = self.df['did_rain'].values\n",
    "        \n",
    "        # We MUST set shuffle=False for time-series data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Calculate imbalance ratio for `scale_pos_weight`\n",
    "        # This helps the model pay more attention to the rare 'rain' class\n",
    "        neg, pos = np.bincount(y)\n",
    "        imbalance_ratio = neg / pos\n",
    "        \n",
    "        # --- 6. Create and Train the Final Pipeline ---\n",
    "        final_pipeline = Pipeline([\n",
    "            ('features', combined_features),\n",
    "            ('xgb_classifier', XGBClassifier(\n",
    "                n_estimators=550,\n",
    "                max_depth=8,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.7,\n",
    "                scale_pos_weight=imbalance_ratio,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        print(\"   -> Fitting XGBoost pipeline... (This may take a moment)\")\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the trained pipeline\n",
    "        joblib.dump(final_pipeline, self.pipeline_path)\n",
    "        print(f\"‚úÖ Pipeline trained and saved to {self.pipeline_path}\")\n",
    "\n",
    "        # --- 7. Evaluate the Pipeline ---\n",
    "        print(\"\\nüìä Evaluating rain prediction (XGBoost) model on Test Set...\")\n",
    "        y_pred_proba = final_pipeline.predict_proba(X_test)[:, 1] # Prob of '1' (rain)\n",
    "        \n",
    "        # Find the best threshold for F1-score\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "        \n",
    "        # Add a small epsilon (1e-9) to avoid division by zero\n",
    "        f1_scores = 2 * recall * precision / (recall + precision + 1e-9)\n",
    "        \n",
    "        # Find the threshold that gives the best F1 score\n",
    "        self.best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        \n",
    "        print(f\"   -> Best Threshold (for F1 Score): {self.best_threshold:.4f}\")\n",
    "        \n",
    "        # Apply the best threshold to get binary predictions\n",
    "        y_pred = (y_pred_proba >= self.best_threshold).astype(int)\n",
    "        \n",
    "        # Print classification metrics\n",
    "        print(f\"   -> Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> F1 Score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"   -> ROC AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "        print(\"   -> Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    def calculate_metrics(self, test, train, model):\n",
    "        \"\"\"\n",
    "        Helper function to calculate regression metrics for Prophet models.\n",
    "        \"\"\"\n",
    "        # Get predictions\n",
    "        train_pred = model.predict(train)\n",
    "        test_pred = model.predict(test)\n",
    "    \n",
    "        y_true = test['y'].values\n",
    "        y_pred = test_pred['yhat'].values\n",
    "    \n",
    "        y_train = train['y'].values\n",
    "        yhat_train = train_pred['yhat'].values\n",
    "    \n",
    "        # Symmetric Mean Absolute Percentage Error\n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "    \n",
    "        metrics = {\n",
    "            'MAE': mean_absolute_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'R2': r2_score(y_true, y_pred),\n",
    "            \"SMAPE\": smape,\n",
    "            'Mean_Error': np.mean(y_pred - y_true),  # Bias\n",
    "            'Training MAE': mean_absolute_error(y_train, yhat_train)\n",
    "        }\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"   -> {metric}: {value:.2f}\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        Main user-facing function to generate a complete forecast.\n",
    "        \n",
    "        Prompts the user for a start date and interval, then returns\n",
    "        the rain probability and the detailed weather forecast.\n",
    "\n",
    "        Returns:\n",
    "            (pd.DataFrame, pd.DataFrame):\n",
    "                - proba_df: DataFrame with rain probabilities and recommendations.\n",
    "                - weather_preds_df: DataFrame with detailed weather forecasts.\n",
    "        \"\"\"\n",
    "        # 1. Load the main rain prediction pipeline\n",
    "        try:\n",
    "            self.pipeline = joblib.load(self.pipeline_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Pipeline file not found at {self.pipeline_path}.\")\n",
    "            print(\"   -> Please run `save_pipeline()` first.\")\n",
    "            return None, None\n",
    "        \n",
    "        # 2. Get the date and interval from the user\n",
    "        start_date = input(\"\\nEnter the start date (YYYY-MM-DD): \")\n",
    "        interval = int(input(\"Enter the number of days to forecast: \"))\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 3. Call the helper function to get the weather forecast for the full interval.\n",
    "        #    This `weather_preds_df` contains all the features needed for the next step.\n",
    "        weather_preds_df = self.predict_func(start_date, interval)\n",
    "\n",
    "        # 4. Use the complete weather forecast to predict the probability of rain.\n",
    "        #    The pipeline receives a DataFrame with multiple rows and 6 columns, just as it expects.\n",
    "        rain_probabilities = self.pipeline.predict_proba(weather_preds_df)\n",
    "\n",
    "        # 5. Format the rain probability results into a clean DataFrame\n",
    "        proba_df = pd.DataFrame(\n",
    "            (rain_probabilities * 100).round(2),\n",
    "            columns=[\"Prob. of No Rain (%)\", \"Prob. of Rain (%)\"],\n",
    "            index=weather_preds_df['date']  # Use the future dates as the index\n",
    "        )\n",
    "        \n",
    "        # 6. Add a human-readable recommendation\n",
    "        #    (Use a default threshold if `save_pipeline` hasn't been run)\n",
    "        best_threshold_percent = (self.best_threshold or 0.5) * 100\n",
    "        \n",
    "        proba_df[\"Recommendation\"] = proba_df['Prob. of Rain (%)'].apply(\n",
    "            lambda x: \"Take an umbrella! ‚òî\" if x >= best_threshold_percent else \"Enjoy the clear skies! ‚òÄÔ∏è\")\n",
    "        \n",
    "\n",
    "        # 7. Return both the rain probabilities and the detailed weather predictions\n",
    "        return proba_df, weather_preds_df.set_index('date')\n",
    "    \n",
    "    def prophet_metrics(self):\n",
    "        \"\"\"\n",
    "        Calculates and prints regression metrics for all the\n",
    "        individual Prophet models.\n",
    "        \"\"\"\n",
    "        print(\"\\nüìà Evaluating individual Prophet (weather) models...\")\n",
    "        \n",
    "        models = self.gathering_models()\n",
    "        if not models:\n",
    "            return\n",
    "\n",
    "        for i, target in enumerate(self.targets):\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"Evaluation Results for: {target}\")\n",
    "            \n",
    "            # Get the data for this target\n",
    "            df_prophet = self._prepare_prophet_df(target)\n",
    "            \n",
    "            # Split the data (must be same split as XGBoost)\n",
    "            train_df, test_df = train_test_split(df_prophet, test_size=0.2, shuffle=False)\n",
    "            \n",
    "            # Calculate and print metrics\n",
    "            self.calculate_metrics(test_df, train_df, models[i])\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "\n",
    "# === PART 3: SCRIPT EXECUTION ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # # --- Phase 1: Fetch Data ---\n",
    "    # print(\"üöÄ NASA GLDAS Data Fetcher & Rain Forecaster\")\n",
    "    # print(\"=\" * 50)\n",
    "    \n",
    "    # # Initialize the fetcher\n",
    "    # fetcher = GLDASFetcher()\n",
    "    # city = input(\"Enter the city name (e.g., 'Cairo, Egypt'): \")\n",
    "    \n",
    "    # location = fetcher.get_location_by_address(city)\n",
    "    # lat = location[\"lat\"]\n",
    "    # lon = location[\"lon\"]\n",
    "    # city_name = location['display_name']\n",
    "\n",
    "    # print(f\"\\nGeocoded {city} to: {city_name} ({lat}, {lon})\")\n",
    "    \n",
    "    # Define a long historical period for robust model training\n",
    "    start_date = \"1984-01-01\"\n",
    "    # Fetch data up to yesterday\n",
    "    end_date = (datetime.now() - timedelta(days=6)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    \n",
    "    # data = fetcher.get_data(\n",
    "    #     lat=lat,\n",
    "    #     lon=lon,\n",
    "    #     start_date=start_date,\n",
    "    #     end_date=end_date,\n",
    "    #     variables=['temp', 'humidity', 'pressure', 'precipitation', 'solar_rad', 'wind_speed','evapotranspiration', 'soil_moisture', 'dew_point']\n",
    "\n",
    "    # )\n",
    "    \n",
    "    if data.empty:\n",
    "        print(\"‚ùå No data retrieved. Exiting script.\")\n",
    "    else:\n",
    "        # Save the data to a CSV file\n",
    "        data_path = \"nasa_daily_weather_data.csv\"\n",
    "        data.to_csv(data_path, index=False)\n",
    "        print(f\"\\n‚úÖ Data successfully saved to {data_path}\")\n",
    "        \n",
    "        # --- Phase 2: Train and Run Forecaster ---\n",
    "        \n",
    "        # Initialize the forecaster with the data we just saved\n",
    "        wf = WeatherForecaster(data_path=data_path)\n",
    "        \n",
    "        # 1. Train and save all the Prophet models (temp, humidity, etc.)\n",
    "        wf.train_and_save_prophet()\n",
    "        \n",
    "        # 2. Evaluate the Prophet models\n",
    "        wf.prophet_metrics()\n",
    "        \n",
    "        # 3. Train and save the main XGBoost rain prediction pipeline\n",
    "        wf.save_pipeline()\n",
    "        \n",
    "        # --- Phase 3: Get a Forecast ---\n",
    "        print(\"\\n\\n\" + \"=\" * 50)\n",
    "        print(\"üéâ All models trained! Let's get a forecast.\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 4. Run the main model function\n",
    "        rain_forecast, weather_forecast = wf.model()\n",
    "        \n",
    "        if rain_forecast is not None:\n",
    "            print(\"\\n--- ‚òî Rain Forecast ---\")\n",
    "            print(rain_forecast)\n",
    "            \n",
    "            print(\"\\n--- üå°Ô∏è Detailed Weather Forecast ---\")\n",
    "            print(weather_forecast.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e971a-fb06-4c7f-b80c-910609ba60e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
